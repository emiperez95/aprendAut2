{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 2 - Árboles de Decisión\n",
    "\n",
    "### Grupo M:\n",
    "     - Leonel Rosano  5.039.791-0\n",
    "     - Emiliano Pérez 4.787.149-2\n",
    "     - Felipe Chavat 4.659.472-2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este laboratorio es construir Árboles de Decisión utilizando el algorítmo _ID3_ y modificandolo para que sea capaz de soportar atributos numéricos. En primera instancia se construye un Árbol de Decisión capaz de predecir clases del conjunto _Iris_. Luego se genera un arbol por cada clase, donde cada árbol tomara el criterio de clasificacion \"una clase versus el resto\".\n",
    "Finalmente se repite el procedimiento haciendo uso del conjunto _Covertype_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Primera parte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que _ID3_ soporte atributos con valores numéricos continuos fue necesario modificar el algorítmo para que sea capaz de discretizar un atributo con estas especificaciones.\n",
    "Para ello, a la hora de considerar un atributo cuantitativo se utilizó un umbral para subdividir el conjunto de entrenamiento en dos (por ejemplo, mayores y menores o igual)\n",
    "Este umbral se obtiene de un conjunto de posibles umbrales calculados de la siguiente forma:\n",
    "Dado un atributo (A), el cual se quiere saber si es la mejor opción en la iteración actual, se ordena el conjunto de entrenamiento (S) según el atributo A y se toma el valor medio de este atributo entre dos tuplas consiguientes cuya clase es distinta.\n",
    "De estos posibles umbrales, el mejor es aquel que maximiza la ganancia.\n",
    "\n",
    "Para medir la ganancia de información de un atributo, el algorítmo _ID3_ utiliza la entropía (_H(S)_), y se calcula la ganancia como la diferencia entre la entropía del conjunto actual y la entropía del conjunto resultante de subdividirlo según el atributo. Sin embargo, vimos que es posible calcular la ganancia de información como la diferencia de la _impureza de Gini_[PONER REFERENCIA] ó la diferencia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preparación del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto _Iris_ consta de 150 instancias en total, las cuales clasifican a la planta Iris en 3 distintas especies: Iris Setosa, Iris Versicolour, Iris Virginica. Los atributos utilizados para clasificar la especie son 4, todos numéricos continuos, por ende, será necesario utilizar el algorítmo ID3 modificado para lograr generar un árbol de decisión capaz de clasificarlas.\n",
    "\n",
    "Dado el conjunto de datos _Iris_, se reorganizan las tuplas de forma aleatoria para lograr una buena distribución de las clases a clasificar. Luego se particiona este conjunto en dos subconjuntos A y B correspondientes al 60% y 40% del conjunto original.\n",
    "\n",
    "El subconjunto A es utilizado para entrenar el Árbol de Decisión y el subconjunto B se utiliza para hacer una evaluación del modelo resultante. No se evalúa el modelo con el mismo conjunto con el que se entrena ya que, de ser así, podríamos estar dentro de un caso de sobre ajuste y no seríamos capaces de identificarlo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Evaluación de los modelos realizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan tres modelos distintos usando para cada uno de estos una métrica distinta a la hora de hallar la ganancia de información para cada atributo.\n",
    "\n",
    "Los resultados que se muestran tienen el siguiente formato:\n",
    "En primera instancia, se mostrará el arbol con toda la información obtenida en cada nodo. Por ejemplo, el nodo\n",
    "`=> 2 >= 3.3, Gain: 0.898 , MCV:  1 , P:  34.286 % --- COE:  [(1, 36), (2, 36), (3, 33)]`\n",
    "indica que es no es una hoja (_=>_), si lo fuera estaría representado por '_->_', la condición para subdividir el conjunto (atributo _2 >= 3.3_), la ganancia generada por el atributo (_Gain_), la clase mas comunmente observada en el conjunto de entrenamiento actual (_MCV_), el porcentaje de la cantidad de resultados con el valor mas comunmente observado (P) y la cantidad de ocurrencias de cada clase en el conjunto de entrenamiento actual (_COE_).\n",
    "\n",
    "Luego, se podrá observar una representación visual del árbol generado para tener una mejor idea de la estructura de este.\n",
    "\n",
    "Por último, se presentará una matriz de confusión para poder hacer observación de que tan bueno es el modelo obtenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Usando Entropía\n",
    "\n",
    "En primera instancia, se genera un árbol utilizando entropía (_Shannon Entropy_) para calcular la ganancia. Los resultados obtenidos son los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 2 >= 2.6, Gain: 0.898 , MCV:  1 , P:  34.286 % --- COE:  [(1, 36), (2, 36), (3, 33)]\n",
      " -> Class: 3 , MCV:  3 , P:  100.0 % --- COE:  [(3, 33)]\n",
      " => 3 >= 1.7, Gain: 0.753 , MCV:  1 , P:  50.0 % --- COE:  [(1, 36), (2, 36)]\n",
      "  => 2 >= 5.3, Gain: 0.125 , MCV:  1 , P:  94.595 % --- COE:  [(1, 35), (2, 2)]\n",
      "   => 0 >= 4.9, Gain: 0.128 , MCV:  1 , P:  97.222 % --- COE:  [(1, 35), (2, 1)]\n",
      "    => 1 >= 2.45, Gain: 1.0 , MCV:  1 , P:  50.0 % --- COE:  [(1, 1), (2, 1)]\n",
      "     -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 1)]\n",
      "     -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 1)]\n",
      "    -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 34)]\n",
      "   -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 1)]\n",
      "  => 2 >= 4.8, Gain: 0.108 , MCV:  2 , P:  97.143 % --- COE:  [(1, 1), (2, 34)]\n",
      "   => 0 >= 5.95, Gain: 0.918 , MCV:  2 , P:  66.667 % --- COE:  [(1, 1), (2, 2)]\n",
      "    -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 1)]\n",
      "    -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 2)]\n",
      "   -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 32)]\n",
      "\n",
      "\n",
      "            ______________2\n",
      "           /               \\\n",
      "    ______3__               3\n",
      "   /         \\\n",
      "  2__         2__\n",
      " /   \\       /   \\\n",
      "2     0     2     0__\n",
      "     / \\         /   \\\n",
      "    2   1       1     1\n",
      "                     / \\\n",
      "                    2   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from main import makeSimpleTree\n",
    "tree = makeSimpleTree('entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión obtenida para este caso es:\n",
    "\n",
    "|-|Iris Setosa |Iris Versicolour |Iris Virginica |\n",
    "|---:|---:|---:|---:|\n",
    "| Iris Setosa |**8** |0 |0 |\n",
    "| Iris Versicolour |2 |**3** |0 |\n",
    "| Iris Virginica |0 |0 |**12** |\n",
    "\n",
    "Valores macro y micro\n",
    "\n",
    "|- |Prec |Rec |Fs 0.5 |\n",
    "|---: |---: |---: |---:|\n",
    "|Micro |0.92 |0.92 |0.92|\n",
    "|Macro |0.933 |0.867 |0.899|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Usando impureza de Gini\n",
    "\n",
    "La impureza de Gini nos da noción de que tan probable es que dos elementos tomados aleatoriamente sean distintos. Cuanto menor sea el valor resultante, mas 'puro' es el conjunto el cual estamos midiendo su impureza.\n",
    "\n",
    "Por ejemplo, dado un conjunto con dos clases distintas\n",
    "\n",
    "| #Class1 | #Class2 | Gini |\n",
    "|---:|---:|------:|\n",
    "|0|5|0|\n",
    "|1|1|0.5|\n",
    "|1|2|0.44|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos haciendo uso de la impureza de Gini son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 2 >= 2.6, Gain: 0.323 , MCV:  1 , P:  34.286 % --- COE:  [(1, 36), (2, 36), (3, 33)]\n",
      " -> Class: 3 , MCV:  3 , P:  100.0 % --- COE:  [(3, 33)]\n",
      " => 3 >= 1.7, Gain: 0.42 , MCV:  1 , P:  50.0 % --- COE:  [(1, 36), (2, 36)]\n",
      "  => 2 >= 5.3, Gain: 0.05 , MCV:  1 , P:  94.595 % --- COE:  [(1, 35), (2, 2)]\n",
      "   => 0 >= 4.9, Gain: 0.026 , MCV:  1 , P:  97.222 % --- COE:  [(1, 35), (2, 1)]\n",
      "    => 1 >= 2.45, Gain: 0.5 , MCV:  1 , P:  50.0 % --- COE:  [(1, 1), (2, 1)]\n",
      "     -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 1)]\n",
      "     -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 1)]\n",
      "    -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 34)]\n",
      "   -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 1)]\n",
      "  => 2 >= 4.8, Gain: 0.017 , MCV:  2 , P:  97.143 % --- COE:  [(1, 1), (2, 34)]\n",
      "   => 0 >= 5.95, Gain: 0.444 , MCV:  2 , P:  66.667 % --- COE:  [(1, 1), (2, 2)]\n",
      "    -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 1)]\n",
      "    -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 2)]\n",
      "   -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 32)]\n",
      "\n",
      "\n",
      "            ______________2\n",
      "           /               \\\n",
      "    ______3__               3\n",
      "   /         \\\n",
      "  2__         2__\n",
      " /   \\       /   \\\n",
      "2     0     2     0__\n",
      "     / \\         /   \\\n",
      "    2   1       1     1\n",
      "                     / \\\n",
      "                    2   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = makeSimpleTree('gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión obtenida para este caso es:\n",
    "\n",
    "|-|Iris Setosa |Iris Versicolour |Iris Virginica |\n",
    "|---:|---:|---:|---:|\n",
    "| Iris Setosa |**8** |0 |0 |\n",
    "| Iris Versicolour |2 |**3** |0 |\n",
    "| Iris Virginica |0 |0 |**12** |\n",
    "\n",
    "Valores macro y micro\n",
    "\n",
    "|- |Prec |Rec |Fs 0.5|\n",
    "|---: |---: |---: |---:|\n",
    "|Micro |0.92 |0.92 |0.92|\n",
    "|Macro |0.933 |0.867 |0.899|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Usando misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 2 >= 2.6, Gain: 0.314 , MCV:  1 , P:  34.286 % --- COE:  [(1, 36), (2, 36), (3, 33)]\n",
      " -> Class: 3 , MCV:  3 , P:  100.0 % --- COE:  [(3, 33)]\n",
      " => 3 >= 1.7, Gain: 0.458 , MCV:  1 , P:  50.0 % --- COE:  [(1, 36), (2, 36)]\n",
      "  => 2 >= 5.3, Gain: 0.027 , MCV:  1 , P:  94.595 % --- COE:  [(1, 35), (2, 2)]\n",
      "   -> Class: 1 , MCV:  1 , P:  97.222 % --- COE:  [(1, 35), (2, 1)]\n",
      "   -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 1)]\n",
      "  -> Class: 2 , MCV:  2 , P:  97.143 % --- COE:  [(1, 1), (2, 34)]\n",
      "\n",
      "\n",
      "    ______2\n",
      "   /       \\\n",
      "  3__       3\n",
      " /   \\\n",
      "2     2\n",
      "     / \\\n",
      "    2   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = makeSimpleTree('misclassification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión resultante:\n",
    "\n",
    "\n",
    "|-|Iris Setosa |Iris Versicolour |Iris Virginica |\n",
    "|---:|---:|---:|---:|\n",
    "| Iris Setosa |**8** |0 |0 |\n",
    "| Iris Versicolour |2 |**3** |0 |\n",
    "| Iris Virginica |0 |0 |**12** |\n",
    "\n",
    "Valores macro y micro\n",
    "\n",
    "|- |Prec |Rec |Fs 0.5|\n",
    "|---: |---: |---: |---:|\n",
    "|Micro |0.92 |0.92 |0.92|\n",
    "|Macro |0.933 |0.867 |0.899|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 5-fold cross validation\n",
    "\n",
    "Se realiza 5-fold cross validation y se evalúa cada modelo obtenido hallando la media armónica de cada uno de estos.\n",
    "Es importante aclarar que para hallar la medida armónica se utiliza el conjunto destinado a evaluación del modelo generado.\n",
    "Los resultados obtenidos son:\n",
    "\n",
    "| - | Micro F Score | Macro F Score |\n",
    "|--:|------------:|------------:|\n",
    "| 0 | **1.0** | **1.0** |\n",
    "| 1 | **1.0** | **1.0** |\n",
    "| 2 | **1.0** | **1.0** |\n",
    "| 3 | **1.0** | **1.0** |\n",
    "| 4 | 0.92 | 0.8987654320987655 |\n",
    "\n",
    "Pudimos observar que en la mayoría de los modelos generados se obtiene el mejor resultado posible. Creemos que se debe a que en los conjuntos de entrenamiento generados el porcentaje de casos distintos fue consistente además de que el algorítmo implementado es suficientemente robusto para saber clasificar estos casos. \n",
    "\n",
    "Al final, utilizamos un conjunto con un total de 20 tuplas que no fue utilizado ni para entrenar ni para evaluar, con el objetivo de asegurar que no estamos en casos de sobre ajuste. Los resultados son los siguientes:\n",
    "\n",
    "| - | Micro Score | Macro Score |\n",
    "|--:|------------:|------------:|\n",
    "| 0 | **1.0** | **1.0** |\n",
    "| 1 | **1.0** | **1.0** |\n",
    "| 2 | **1.0** | **1.0** |\n",
    "| 3 | **1.0** | **1.0** |\n",
    "| 4 | 0.9 | 0.901565995525727 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Conclusiones\n",
    "\n",
    "Fuimos capaces de clasificar de forma correcta el 92% de las tuplas del conjunto de evaluación, por lo que consideramos que los modelos realizados tienen un buen resultado.\n",
    "También creemos que la cantidad de tuplas que contiene el conjunto utilizado (conjunto _Iris_) no es tan grande como para poder reconocer posibles diferencias a la hora de utilizar distintas métricas. Por la misma razón, consideramos no realizar post procesamiento (post-pruning) a los árboles obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Segunda parte\n",
    "\n",
    "Para la realización de este paso, se implementa un algorítmo (clase llamada _PoolTree_) capaz de almacenar un modelo de uno versus todos para cada clase existente en el conjunto de datos, y que es capaz de ejecutar una clasificación en función de estos modelos.\n",
    "Para el caso del conjunto _Iris_, el resultado es una instancia de la clase _PoolTree_ que contiene tres modelos distintos, uno que clasifica a las _Iris Setosa_ versus las demas, y analogamente los otros dos modelos con _Iris Versicolour_ e _Iris Virginica_.\n",
    "A la hora de implementar la clasificación de este conjunto de modelos, fue necesario definir un criterio para toma de decisiones en caso de que existiese un conflicto de predicción (mas de un modelo reclamando la tupla a predecir).\n",
    "\n",
    "### 3.1 Criterio de Clasificación\n",
    "\n",
    "A cada nodo del arbol generado se le asignó el porcentaje correspondiente a la cantidad de ocurrencias de la clase dominante. Este porcentaje se utiliza cuando, dado un bosque y un ejemplo, se obtienen más de un positivo. En este caso, el criterio por el cual se decidirá a cuál árbol creerle es el de mayor porcentaje.\n",
    "De la misma forma, en caso de que ningún árbol reclame la clase, se tomará a aquel cuyo porcentaje sea menor (aquel cuya probabilidad de que sea un falso negativo es mayor).\n",
    "\n",
    "En el caso de que empaten en pocentaje, se tomara el primero.\n",
    "\n",
    "Ejemplo:\n",
    "Dada una tupla correspondiente a una _Iris Setosa_ y un bosque que contiene tres modelos de uno versus todos (uno por cada clase de _Iris_). Si al clasificar, el caso es el siguiente:\n",
    "\n",
    "| - | Result | Percentage |\n",
    "|--:|-------:|-----------:|\n",
    "|Model Setosa|True|**97%**|\n",
    "|Model Versicolour|True|53%|\n",
    "|Model Virginica|False|96%|\n",
    "\n",
    "\n",
    "Entonces la predicción (usando el criterio antes nombrado) dará como resultado _Iris Setosa_\n",
    "\n",
    "### 3.2 Preparación del conjunto de entrenamiento\n",
    "\n",
    "Para cada modelo de una clase versus las demas se adaptó el conjunto de entrenamiento para que el valor fuese verdadero (en caso de ser la clase que se quiere clasificar) o falso (en caso contrario).\n",
    "Es decir, para generar el modelo de _Iris Setosa_ versus las demas, si en el conjunto de entrenamiento original se tenían las tuplas\n",
    "\n",
    "```\n",
    "5.0,3.3,1.4,0.2,Iris-setosa\n",
    "7.0,3.2,4.7,1.4,Iris-versicolor\n",
    "6.3,3.4,5.6,2.4,Iris-virginica\n",
    "```\n",
    "entonces, en el nuevo conjunto adaptado para generar este modelo, se tendrían las siguientes tuplas:\n",
    "\n",
    "```\n",
    "5.0,3.3,1.4,0.2,1\n",
    "7.0,3.2,4.7,1.4,0\n",
    "6.3,3.4,5.6,2.4,0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Evaluación\n",
    "\n",
    "#### 3.3.1 Evaluación normal\n",
    "\n",
    "Nuevamente, los resultados obtenidos usados para las tres métricas implementadas fueron los mismos, por lo tanto, se copian los resultados una sola vez.\n",
    "\n",
    "Matriz de Confusión:\n",
    "\n",
    "|-|Iris Setosa |Iris Versicolour |Iris Virginica |\n",
    "|---:|---:|---:|---:|\n",
    "| Iris Setosa |**8** |0 |0 |\n",
    "| Iris Versicolour |2 |**3** |0 |\n",
    "| Iris Virginica |0 |0 |**12** |\n",
    "\n",
    "Valores macro y micro:\n",
    "\n",
    "|- |Prec |Rec |Fs 0.5|\n",
    "|---: |---: |---: |---:|\n",
    "|Micro |0.92 |0.92 |0.92|\n",
    "|Macro |0.933 |0.867 |0.899|\n",
    "\n",
    "##### 3.3.2 Evaluación realizando 5-fold cross validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Presentar los distintos experimentos que se realizan y los resultados que se obtienen.\n",
    "\n",
    "- La información de los resultados se presenta en tablas y en gráficos, de acuerdo a su naturaleza. Por ejemplo:\n",
    "\n",
    "_En la gráfica 1, se observa el error cuadrático total del conjunto de entrenamiento a medida que pasan los juegos para el oponente X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Conclusiones\n",
    "Podemos observar que para los valores micro se obtuvo un 92%, mientras que para medidas macro fue del 93.3%.\n",
    "Los valores indican que este metodo tuvo una buena respuesta, dado el acotado conjunto. \n",
    "Esperabamos que este metodo se destacara frente al metodo de la parte anterior, pero observando los resultados obtenididos, podemos concluir que tanto el metodo de la parte anterior, como este se comportan de forma similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Tercera parte \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 2.1 Preparación del conjunto de entrenamiento\n",
    "Para esta parte se tomo le conjunto _Covertype_. El cual consta de 581.012 instancias de 10 atributos cuantitativos, 2 atributos cualitativos (4 y 40 bits), y 7 distintas clases.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
