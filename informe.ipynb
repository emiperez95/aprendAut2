{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 2 - Árboles de Decisión\n",
    "\n",
    "### Grupo M:\n",
    "     - Leonel Rosano  5.039.791-0\n",
    "     - Emiliano Pérez 4.787.149-2\n",
    "     - Felipe Chavat 4.659.472-2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este laboratorio es construir Árboles de Decisión utilizando el algorítmo _ID3_ y modificandolo para que sea capaz de soportar atributos numéricos. En primera instancia se construye un Árbol de Decisión capaz de predecir clases del conjunto _Iris_. Luego se genera un arbol por cada clase, donde cada árbol tomara el criterio de clasificacion \"una clase versus el resto\".\n",
    "Finalmente se repite el procedimiento haciendo uso del conjunto _Covertype_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Primera parte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que _ID3_ soporte atributos con valores numéricos continuos fue necesario modificar el algorítmo para que sea capaz de discretizar un atributo con estas especificaciones.\n",
    "Para ello, a la hora de considerar un atributo cuantitativo se utilizó un umbral para subdividir el conjunto de entrenamiento en dos (por ejemplo, mayores y menores o igual)\n",
    "Este umbral se obtiene de un conjunto de posibles umbrales calculados de la siguiente forma:\n",
    "Dado un atributo (A), el cual se quiere saber si es la mejor opción en la iteración actual, se ordena el conjunto de entrenamiento (S) según el atributo A y se toma el valor medio de este atributo entre dos tuplas consiguientes cuya clase es distinta.\n",
    "De estos posibles umbrales, el mejor es aquel que maximiza la ganancia.\n",
    "\n",
    "Para medir la ganancia de información de un atributo, el algorítmo _ID3_ utiliza la entropía (_H(S)_), y se calcula la ganancia como la diferencia entre la entropía del conjunto actual y la entropía del conjunto resultante de subdividirlo según el atributo. Sin embargo, vimos que es posible calcular la ganancia de información como la diferencia de la _impureza de Gini_[PONER REFERENCIA] ó la diferencia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preparación del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto _Iris_ consta de 150 instancias en total, las cuales clasifican a la planta Iris en 3 distintas especies: Iris Setosa, Iris Versicolour, Iris Virginica. Los atributos utilizados para clasificar la especie son 4, todos numéricos continuos, por ende, será necesario utilizar el algorítmo ID3 modificado para lograr generar un árbol de decisión capaz de clasificarlas.\n",
    "\n",
    "Dado el conjunto de datos _Iris_, se reorganizan las tuplas de forma aleatoria para lograr una buena distribución de las clases a clasificar. Luego se particiona este conjunto en dos subconjuntos A y B correspondientes al 60% y 40% del conjunto original.\n",
    "\n",
    "El subconjunto A es utilizado para entrenar el Árbol de Decisión y el subconjunto B se utiliza para hacer una evaluación del modelo resultante. No se evalúa el modelo con el mismo conjunto con el que se entrena ya que, de ser así, podríamos estar dentro de un caso de sobre ajuste y no seríamos capaces de identificarlo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Evaluación de los modelos realizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan tres modelos distintos usando para cada uno de estos una métrica distinta a la hora de hallar la ganancia de información para cada atributo.\n",
    "\n",
    "Los resultados que se muestran tienen el siguiente formato:\n",
    "En primera instancia, se mostrará el arbol con toda la información obtenida en cada nodo. Por ejemplo, el nodo\n",
    "`=> 2 >= 3.3, Gain: 0.898 , MCV:  1 , P:  34.286 % --- COE:  [(1, 36), (2, 36), (3, 33)]`\n",
    "indica que es no es una hoja (_=>_), si lo fuera estaría representado por '_->_', la condición para subdividir el conjunto (atributo _2 >= 3.3_), la ganancia generada por el atributo (_Gain_), la clase mas comunmente observada en el conjunto de entrenamiento actual (_MCV_), el porcentaje de la cantidad de resultados con el valor mas comunmente observado (P) y la cantidad de ocurrencias de cada clase en el conjunto de entrenamiento actual (_COE_).\n",
    "\n",
    "Luego, se podrá observar una representación visual del árbol generado para tener una mejor idea de la estructura de este.\n",
    "\n",
    "Por último, se presentará una matriz de confusión para poder hacer observación de que tan bueno es el modelo obtenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Usando Entropía\n",
    "\n",
    "En primera instancia, se genera un árbol utilizando entropía (_Shannon Entropy_) para calcular la ganancia. Los resultados obtenidos son los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 2 >= 2.6, Gain: 0.898 , MCV:  1 , P:  34.286 % --- COE:  [(1, 36), (2, 36), (3, 33)]\n",
      " -> Class: 3 , MCV:  3 , P:  100.0 % --- COE:  [(3, 33)]\n",
      " => 3 >= 1.7, Gain: 0.753 , MCV:  1 , P:  50.0 % --- COE:  [(1, 36), (2, 36)]\n",
      "  => 1 >= 2.6, Gain: 0.1 , MCV:  1 , P:  94.595 % --- COE:  [(1, 35), (2, 2)]\n",
      "   => 0 >= 6.15, Gain: 0.094 , MCV:  1 , P:  81.818 % --- COE:  [(1, 9), (2, 2)]\n",
      "    -> Class: 1 , MCV:  1 , P:  75.0 % --- COE:  [(1, 6), (2, 2)]\n",
      "    -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 3)]\n",
      "   -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 26)]\n",
      "  => 0 >= 5.95, Gain: 0.076 , MCV:  2 , P:  97.143 % --- COE:  [(1, 1), (2, 34)]\n",
      "   => 1 >= 3.1, Gain: 0.65 , MCV:  2 , P:  83.333 % --- COE:  [(1, 1), (2, 5)]\n",
      "    -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 5)]\n",
      "    -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 1)]\n",
      "   -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 29)]\n",
      "\n",
      "\n",
      "            __________2\n",
      "           /           \\\n",
      "    ______3__           3\n",
      "   /         \\\n",
      "  0__         1__\n",
      " /   \\       /   \\\n",
      "2     1     1     0\n",
      "     / \\         / \\\n",
      "    1   2       1   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from main import makeSimpleTree\n",
    "tree = makeSimpleTree('entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión obtenida para este caso es:\n",
    "\n",
    "|-|Iris Setosa |Iris Versicolour |Iris Virginica |\n",
    "|---:|---:|---:|---:|\n",
    "| Iris Setosa |**8** |0 |0 |\n",
    "| Iris Versicolour |2 |**3** |0 |\n",
    "| Iris Virginica |0 |0 |**12** |\n",
    "\n",
    "Valores macro y micro\n",
    "\n",
    "|- |Prec |Rec |Fs 0.5 |\n",
    "|---: |---: |---: |---:|\n",
    "|Micro |0.92 |0.92 |0.92|\n",
    "|Macro |0.933 |0.867 |0.899|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Usando impureza de Gini\n",
    "\n",
    "La impureza de Gini nos da noción de que tan probable es que dos elementos tomados aleatoriamente sean distintos. Cuanto menor sea el valor resultante, mas 'puro' es el conjunto el cual estamos midiendo su impureza.\n",
    "\n",
    "Por ejemplo, dado un conjunto con dos clases distintas\n",
    "\n",
    "| #Class1 | #Class2 | Gini |\n",
    "|---:|---:|------:|\n",
    "|0|5|0|\n",
    "|1|1|0.5|\n",
    "|1|2|0.44|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos haciendo uso de la impureza de Gini son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 2 >= 2.6, Gain: 0.323 , MCV:  1 , P:  34.286 % --- COE:  [(1, 36), (2, 36), (3, 33)]\n",
      " -> Class: 3 , MCV:  3 , P:  100.0 % --- COE:  [(3, 33)]\n",
      " => 3 >= 1.7, Gain: 0.42 , MCV:  1 , P:  50.0 % --- COE:  [(1, 36), (2, 36)]\n",
      "  => 0 >= 4.9, Gain: 0.023 , MCV:  1 , P:  94.595 % --- COE:  [(1, 35), (2, 2)]\n",
      "   => 1 >= 2.45, Gain: 0.5 , MCV:  1 , P:  50.0 % --- COE:  [(1, 1), (2, 1)]\n",
      "    -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 1)]\n",
      "    -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 1)]\n",
      "   => 1 >= 2.6, Gain: 0.005 , MCV:  1 , P:  97.143 % --- COE:  [(1, 34), (2, 1)]\n",
      "    -> Class: 1 , MCV:  1 , P:  88.889 % --- COE:  [(1, 8), (2, 1)]\n",
      "    -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 26)]\n",
      "  => 0 >= 5.95, Gain: 0.008 , MCV:  2 , P:  97.143 % --- COE:  [(1, 1), (2, 34)]\n",
      "   => 1 >= 3.1, Gain: 0.278 , MCV:  2 , P:  83.333 % --- COE:  [(1, 1), (2, 5)]\n",
      "    -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 5)]\n",
      "    -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 1)]\n",
      "   -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 29)]\n",
      "\n",
      "\n",
      "            ______________2\n",
      "           /               \\\n",
      "    ______3______           3\n",
      "   /             \\\n",
      "  0__           __0__\n",
      " /   \\         /     \\\n",
      "2     1       1       1\n",
      "     / \\     / \\     / \\\n",
      "    1   2   1   1   2   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = makeSimpleTree('gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión obtenida para este caso es:\n",
    "\n",
    "|-|Iris Setosa |Iris Versicolour |Iris Virginica |\n",
    "|---:|---:|---:|---:|\n",
    "| Iris Setosa |**8** |0 |0 |\n",
    "| Iris Versicolour |2 |**3** |0 |\n",
    "| Iris Virginica |0 |0 |**12** |\n",
    "\n",
    "Valores macro y micro\n",
    "\n",
    "|- |Prec |Rec |Fs 0.5|\n",
    "|---: |---: |---: |---:|\n",
    "|Micro |0.92 |0.92 |0.92|\n",
    "|Macro |0.933 |0.867 |0.899|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Usando misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 2 >= 2.6, Gain: 0.314 , MCV:  1 , P:  34.286 % --- COE:  [(1, 36), (2, 36), (3, 33)]\n",
      " -> Class: 3 , MCV:  3 , P:  100.0 % --- COE:  [(3, 33)]\n",
      " => 3 >= 1.7, Gain: 0.458 , MCV:  1 , P:  50.0 % --- COE:  [(1, 36), (2, 36)]\n",
      "  => 1 >= 2.6, Gain: 0.0 , MCV:  1 , P:  94.595 % --- COE:  [(1, 35), (2, 2)]\n",
      "   => 0 >= 6.15, Gain: -0.0 , MCV:  1 , P:  81.818 % --- COE:  [(1, 9), (2, 2)]\n",
      "    -> Class: 1 , MCV:  1 , P:  75.0 % --- COE:  [(1, 6), (2, 2)]\n",
      "    -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 3)]\n",
      "   -> Class: 1 , MCV:  1 , P:  100.0 % --- COE:  [(1, 26)]\n",
      "  => 1 >= 3.2, Gain: 0.0 , MCV:  2 , P:  97.143 % --- COE:  [(1, 1), (2, 34)]\n",
      "   => 0 >= 5.9, Gain: -0.0 , MCV:  2 , P:  96.552 % --- COE:  [(1, 1), (2, 28)]\n",
      "    -> Class: 2 , MCV:  2 , P:  83.333 % --- COE:  [(1, 1), (2, 5)]\n",
      "    -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 23)]\n",
      "   -> Class: 2 , MCV:  2 , P:  100.0 % --- COE:  [(2, 6)]\n",
      "\n",
      "\n",
      "            __________2\n",
      "           /           \\\n",
      "    ______3__           3\n",
      "   /         \\\n",
      "  1__         1__\n",
      " /   \\       /   \\\n",
      "2     0     1     0\n",
      "     / \\         / \\\n",
      "    2   2       1   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = makeSimpleTree('misclassification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión resultante:\n",
    "\n",
    "\n",
    "|-|Iris Setosa |Iris Versicolour |Iris Virginica |\n",
    "|---:|---:|---:|---:|\n",
    "| Iris Setosa |**8** |0 |0 |\n",
    "| Iris Versicolour |2 |**3** |0 |\n",
    "| Iris Virginica |0 |0 |**12** |\n",
    "\n",
    "Valores macro y micro\n",
    "\n",
    "|- |Prec |Rec |Fs 0.5|\n",
    "|---: |---: |---: |---:|\n",
    "|Micro |0.92 |0.92 |0.92|\n",
    "|Macro |0.933 |0.867 |0.899|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 5-fold cross validation\n",
    "\n",
    "Se realiza 5-fold cross validation y se evalúa cada modelo obtenido hallando la media armónica de cada uno de estos.\n",
    "Es importante aclarar que para hallar la medida armónica se utiliza el conjunto destinado a evaluación del modelo generado.\n",
    "Los resultados obtenidos son:\n",
    "\n",
    "| - | Micro F Score | Macro F Score |\n",
    "|--:|------------:|------------:|\n",
    "| 0 | **1.0** | **1.0** |\n",
    "| 1 | **1.0** | **1.0** |\n",
    "| 2 | **1.0** | **1.0** |\n",
    "| 3 | **1.0** | **1.0** |\n",
    "| 4 | 0.92 | 0.8987654320987655 |\n",
    "\n",
    "Pudimos observar que en la mayoría de los modelos generados se obtiene el mejor resultado posible. Creemos que se debe a que en los conjuntos de entrenamiento generados el porcentaje de casos distintos fue consistente además de que el algorítmo implementado es suficientemente robusto para saber clasificar estos casos. \n",
    "\n",
    "Al final, utilizamos un conjunto con un total de 20 tuplas que no fue utilizado ni para entrenar ni para evaluar, con el objetivo de asegurar que no estamos en casos de sobre ajuste. Los resultados son los siguientes:\n",
    "\n",
    "| - | Micro Score | Macro Score |\n",
    "|--:|------------:|------------:|\n",
    "| 0 | **1.0** | **1.0** |\n",
    "| 1 | **1.0** | **1.0** |\n",
    "| 2 | **1.0** | **1.0** |\n",
    "| 3 | **1.0** | **1.0** |\n",
    "| 4 | 0.9 | 0.901565995525727 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Conclusiones\n",
    "\n",
    "Fuimos capaces de clasificar de forma correcta el 92% de las tuplas del conjunto de evaluación, por lo que consideramos que los modelos realizados tienen un buen resultado.\n",
    "También creemos que la cantidad de tuplas que contiene el conjunto utilizado (conjunto _Iris_) no es tan grande como para poder reconocer posibles diferencias a la hora de utilizar distintas métricas. Por la misma razón, consideramos no realizar post procesamiento (post-pruning) a los árboles obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Segunda parte\n",
    "\n",
    "Para la realización de este paso, se implementa un algorítmo (clase llamada _PoolTree_) capaz de almacenar un modelo de uno versus todos para cada clase existente en el conjunto de datos, y que es capaz de ejecutar una clasificación en función de estos modelos.\n",
    "Para el caso del conjunto _Iris_, el resultado es una instancia de la clase _PoolTree_ que contiene tres modelos distintos, uno que clasifica a las _Iris Setosa_ versus las demas, y analogamente los otros dos modelos con _Iris Versicolour_ e _Iris Virginica_.\n",
    "A la hora de implementar la clasificación de este conjunto de modelos, fue necesario definir un criterio para toma de decisiones en caso de que existiese un conflicto de predicción (mas de un modelo reclamando la tupla a predecir).\n",
    "\n",
    "### 3.1 Criterio de Clasificación\n",
    "\n",
    "A cada nodo del arbol generado se le asignó el porcentaje correspondiente a la cantidad de ocurrencias de la clase dominante. Este porcentaje se utiliza cuando, dado un bosque y un ejemplo, se obtienen más de un positivo. En este caso, el criterio por el cual se decidirá a cuál árbol creerle es el de mayor porcentaje.\n",
    "De la misma forma, en caso de que ningún árbol reclame la clase, se tomará a aquel cuyo porcentaje sea menor (aquel cuya probabilidad de que sea un falso negativo es mayor).\n",
    "\n",
    "En el caso de que empaten en pocentaje, se tomara el primero.\n",
    "\n",
    "Ejemplo:\n",
    "Dada una tupla correspondiente a una _Iris Setosa_ y un bosque que contiene tres modelos de uno versus todos (uno por cada clase de _Iris_). Si al clasificar, el caso es el siguiente:\n",
    "\n",
    "| - | Result | Percentage |\n",
    "|--:|-------:|-----------:|\n",
    "|Model Setosa|True|**97%**|\n",
    "|Model Versicolour|True|53%|\n",
    "|Model Virginica|False|96%|\n",
    "\n",
    "\n",
    "Entonces la predicción (usando el criterio antes nombrado) dará como resultado _Iris Setosa_\n",
    "\n",
    "### 3.2 Preparación del conjunto de entrenamiento\n",
    "\n",
    "Para cada modelo de una clase versus las demas se adaptó el conjunto de entrenamiento para que el valor fuese verdadero (en caso de ser la clase que se quiere clasificar) o falso (en caso contrario).\n",
    "Es decir, para generar el modelo de _Iris Setosa_ versus las demas, si en el conjunto de entrenamiento original se tenían las tuplas\n",
    "\n",
    "```\n",
    "5.0,3.3,1.4,0.2,Iris-setosa\n",
    "7.0,3.2,4.7,1.4,Iris-versicolor\n",
    "6.3,3.4,5.6,2.4,Iris-virginica\n",
    "```\n",
    "entonces, en el nuevo conjunto adaptado para generar este modelo, se tendrían las siguientes tuplas:\n",
    "\n",
    "```\n",
    "5.0,3.3,1.4,0.2,1\n",
    "7.0,3.2,4.7,1.4,0\n",
    "6.3,3.4,5.6,2.4,0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Evaluación\n",
    "\n",
    "#### 3.3.1 Evaluación normal\n",
    "\n",
    "Nuevamente, los resultados obtenidos usados para las tres métricas implementadas fueron los mismos, por lo tanto, se copian los resultados una sola vez.\n",
    "\n",
    "Matriz de Confusión:\n",
    "\n",
    "|-|Iris Setosa |Iris Versicolour |Iris Virginica |\n",
    "|---:|---:|---:|---:|\n",
    "| Iris Setosa |**8** |0 |0 |\n",
    "| Iris Versicolour |2 |**3** |0 |\n",
    "| Iris Virginica |0 |0 |**12** |\n",
    "\n",
    "Valores macro y micro:\n",
    "\n",
    "|- |Prec |Rec |Fs 0.5|\n",
    "|---: |---: |---: |---:|\n",
    "|Micro |0.92 |0.92 |0.92|\n",
    "|Macro |0.933 |0.867 |0.899|\n",
    "\n",
    "##### 3.3.2 Evaluación realizando 5-fold cross validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Presentar los distintos experimentos que se realizan y los resultados que se obtienen.\n",
    "\n",
    "- La información de los resultados se presenta en tablas y en gráficos, de acuerdo a su naturaleza. Por ejemplo:\n",
    "\n",
    "_En la gráfica 1, se observa el error cuadrático total del conjunto de entrenamiento a medida que pasan los juegos para el oponente X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Conclusiones\n",
    "Podemos observar que para los valores micro se obtuvo un 92%, mientras que para medidas macro fue del 93.3%.\n",
    "Los valores indican que este metodo tuvo una buena respuesta, dado el acotado conjunto. \n",
    "Esperabamos que este metodo se destacara frente al metodo de la parte anterior, pero observando los resultados obtenididos, podemos concluir que tanto el metodo de la parte anterior, como este se comportan de forma similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Tercera parte \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta etapa se repite el procedimiento que se siguió en la parte (a) y (b) pero haciendo uso del conjunto de datos _CoverType_.\n",
    "En comparación con las partes anteriores, el conjunto tiene una cantidad de tuplas significativamente mayor al conjunto antes utilizado, esto nos permitió poder experimentar con algunas variaciones en el algorítmo con el objetivo de mejorar el puntaje final obtenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Preparación del conjunto de datos\n",
    "Para esta parte se tomo le conjunto _Covertype_. El cual consta de 581.012 instancias de 10 atributos cuantitativos, 2 atributos cualitativos (de tipo one-hot con 4 y 40 bits), y 7 distintas clases.\n",
    "Se procedió a subdividir el conjunto en 3 subconjuntos. El primero correspondiente al 60% del conjunto original y los siguientes dos al 20%. El primero se utiliza para entrenar, el segundo se utiliza para realizar evaluación y experimentación y el tercero para hacer una prueba final con el modelo elegido para asegurar que no se está en un caso de sobre ajuste.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Evaluación\n",
    "\n",
    "En un principio se prueba el algorítmo sin modificaciones (solo las necesarias para poder construir un árbol de decisión capaz de procesar el conjunto de datos). Luego, con el objetivo de mejorar el resultado obtenido, se agrega al algorítmo la capacidad de poder reutilizar atributos ya procesados.\n",
    "\n",
    "Con el fin de explorar el espacio de soluciones posibles lo mejor posible, se generan modelos variando distintos parámetros para lograr todas las posibles combinaciones (producto cartesiano). Las diferentes combinaciones se aplicaron sobre las siguientes variables:\n",
    "- Metrica utilizada\n",
    "    - Entropía\n",
    "    - Misclassification\n",
    "- Método\n",
    "    - Cross validation\n",
    "    - Binary Forest\n",
    "    - Single tree con normal validation\n",
    "- Reutilización de atributos\n",
    "    - Si (variando el umbral)\n",
    "    - No\n",
    "- Cantidad de tuplas de entrenamiento\n",
    "\n",
    "En particular, cabe aclarar que en caso de reutilización de atributos no se utilizó la métrica de _Misclassification_ su uso podría generar loops infinitos, ya que puede generar un caso en el se crean nuevos nodos a partir de una subdivisión del conjunto que genera un subconjunto vacío y otro igual al anterior. \n",
    "\n",
    "Podría haberse utilizado cross-validation con binary forest, pero se optó por no realizarse debido a la complejidad computacional que esto requería.\n",
    "\n",
    "Los distintos modelos se generan a partir de conjuntos de entrenamiento con una cantidad distinta de tuplas. Los distintos tamaños utilizados fueron 5.000 (5k), 50.000 (50k) y el total del conjunto (500k).\n",
    "Si bien creemos que un tamaño mayor llevaría a mejores resultados, utilizamos cantidades menores para poder verificar esta creencia, y para poder observar cual es la ganancia en aciertos obtenida al aumentar la cantidad de tuplas en el conjunto de entrenamiento.\n",
    "\n",
    "Finalmente, luego de obtenido el modelo que presenta mejores resultados, se utilizará el tercer conjunto generado a partir del conjunto de datos para tener un puntaje del mismo para conocer realmente que tan bueno es.\n",
    "\n",
    "#### 4.2.1 Evaluación sin modificaciones\n",
    "\n",
    "En este paso, se utiliza el algorítmo de generación del clasificador que se utilizó en las partes (a) y (b).\n",
    "Se prueba generar modelos utilizando distintas cantidades de tuplas para entrenar y se comparan los resultados:\n",
    "\n",
    "\n",
    "|Metric| Method |5-Fold C.V.| #Tuples to train |Macro Prec|Macro Rec| Macro F(0.5) |Micro Prec|Micro Rec| Micro F(0.5) |\n",
    "|-----:|-------:|-----:|-----------------:|-------------:|-------------:|--:|--:|--:|--:|\n",
    "|Entropy|CV0|Yes|5k        |0.478     |0.426    |0.45     |0.649    |0.649    |0.649| \n",
    "|Entropy|CV1|Yes|5k        |0.454     |0.408    |0.43     |0.638    |0.638    |0.638 |\n",
    "|Entropy|CV2|Yes|5k        |0.465     |0.413    |0.438    |0.641    |0.641    |0.641| \n",
    "|Entropy|CV3|Yes|5k        |0.464     |0.417    |0.439    |0.644    |0.644    |0.644| \n",
    "|Entropy|CV4|Yes|5k        |0.453     |0.412    |0.431    |0.636    |0.636    |0.636|\n",
    "|Entropy|Normal|No|5k      |0.458     |0.413    |0.434    |0.64     |0.64     |0.64|\n",
    "|Entropy|Binary Tree|No|5k |0.484     |0.468    |0.476    |0.698|0.698|0.698|\n",
    "|Misclass|CV0|Yes|5k       |0.581     |0.436    |0.498    |0.692    |0.692    |0.692|\n",
    "|Misclass|CV1|Yes|5k       |0.542     |0.415    |0.47     |0.687    |0.687    |0.687|\n",
    "|Misclass|CV2|Yes|5k       |0.556     |0.411    |0.473    |0.683    |0.683    |0.683|\n",
    "|Misclass|CV3|Yes|5k       |0.518    |0.397    |0.45|0.683     |0.683    |0.683    |\n",
    "|Misclass|CV4|Yes|5k       |0.58     |0.426    |0.491|0.69      |0.69     |0.69     |\n",
    "|Misclass|Normal|No|5k     |0.549    |0.413    |0.471|0.686     |0.686    |0.686    |\n",
    "|Misclass|Binary Tree|No|5k|0.484    |0.468    |0.476|0.698 |0.698|0.698|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Evaluación haciendo reutilización de atributos\n",
    "\n",
    "El algoritmo sin modificaciones no presenta malos resultados, sin embargo, consideramos que aún podría mejorarse significativamente.\n",
    "Al hacer el análisis de cuáles podrían ser las razones de que el porcentaje de tuplas que predice correctamente no sea tan bueno. Se observó que si se toma un solo umbral por atributo, se están perdiendo posibles divisiones del conjunto, los cuales pueden generar mejores resultados.\n",
    "\n",
    "Por ejemplo, supongamos que tenemos un conjunto en el cual, dado el mejor umbral, obtenemos dos subconjuntos A y B en los cuales, el conjunto A contiene una alta homogeneidad de clases. Utilizando el algoritmo primeramente utilizado, solo se generarían estas dos particiones (si el caso es que este genera la mejor ganancia). Pero qué pasaría si en el segundo subconjunto (B) también existe un posible umbral para el cual las subdivisiones generadas dan un resultado también homogéneo. En este caso, habríamos descartado la posibilidad de realizarlo, ya que previamente habríamos descartado el atributo.\n",
    "\n",
    "La modificación realizada para atacar este problema fue no descartar el atributo si la ganancia generada por este es mayor que una constante predefinida (entThresh), que llamamos umbral.\n",
    "Al analizar el funcionamiento del método planteado, \n",
    "\n",
    "Pudimos observar que al tomar una ganancia mínima para decidir si descartar al atributo, los resultados mejoran notoriamente. Esto se debe a que la información que genera el atributo es mayor a la obtenida por un solo umbral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetición con umbral 0.1\n",
    "\n",
    "|Metric| Method |5-Fold C.V.| #Tuples to train |Macro Prec|Macro Rec| Macro F(0.5) |Micro Prec|Micro Rec| Micro F(0.5) |\n",
    "|-----:|-------:|-----:|-----------------:|-------------:|-------------:|--:|--:|--:|--:|\n",
    "|Entropy|CV0|Yes|5k|0.555    |0.454      |0.5|0.678    |0.678    |0.678  |\n",
    "|Entropy|CV1|Yes|5k|  0.469        |0.41    |0.437|0.662    |0.662       | 0.662       |\n",
    "|Entropy|CV2|Yes|5k|0.494        |0.418    |0.453|0.664    |0.664       | 0.664       |\n",
    "|Entropy|CV3|Yes|5k|0.486          |0.408    |0.444|0.662    |0.662       | 0.662      |\n",
    "|Entropy|CV4|Yes|5k|0.471          |0.417    |0.442|0.666    |0.666       | 0.666       |\n",
    "|Entropy|Normal|No|5k|0.481         |0.414    |0.445|0.663   | 0.663     | 0.663       |\n",
    "|Entropy|Binary Tree|No|5k| 0.294|       0.243|    0.266| 0.63 |    0.63|    0.63     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetición con umbral 0.01\n",
    "\n",
    "|Metric| Method |5-Fold C.V.| #Tuples to train |Macro Prec|Macro Rec| Macro F(0.5) |Micro Prec|Micro Rec| Micro F(0.5) |\n",
    "|-----:|-------:|-----:|-----------------:|-------------:|-------------:|--:|--:|--:|--:|\n",
    "|Entropy|CV0|Yes|5k       |0.515    |0.488    |0.501|0.666    |0.666    |0.666 |\n",
    "|Entropy|CV1|Yes|5k       |0.43    |0.412    |0.421|0.606    |0.606    |0.606 |\n",
    "|Entropy|CV2|Yes|5k       |0.447    |0.416    |0.431|0.603    |0.603    |0.603 |\n",
    "|Entropy|CV3|Yes|5k       |0.438    |0.408    |0.422| 0.604    |0.604    |0.604 |\n",
    "|Entropy|CV4|Yes|5k       |0.425     |0.41    |0.417|0.606    |0.606    |0.606 |\n",
    "|Entropy|Normal|No|5k     |0.435    |0.412|    0.423| 0.604  |  0.604    |0.604 |\n",
    "|Entropy|Binary Tree|No|5k|0.33    |0.279    |0.302|  0.51     |0.51     |0.51 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetición umbral 0.001\n",
    "\n",
    "|Metric| Method |5-Fold C.V.| #Tuples to train |Macro Prec|Macro Rec| Macro F(0.5) |Micro Prec|Micro Rec| Micro F(0.5) |\n",
    "|-----:|-------:|-----:|-----------------:|-------------:|-------------:|--:|--:|--:|--:|\n",
    "|Entropy|CV0|Yes|5k|0.515    |0.488    |0.501|0.666    |0.666   | 0.666 |\n",
    "|Entropy|CV1|Yes|5k|0.43    |0.412|    0.421|0.606    |0.606    |0.606 |\n",
    "|Entropy|CV2|Yes|5k|0.447  |  0.416|    0.431| 0.603    |0.603   | 0.603 |\n",
    "|Entropy|CV3|Yes|5k|0.438   | 0.408 |   0.422|0.604    |0.604    |0.604 |\n",
    "|Entropy|CV4|Yes|5k| 0.425  | 0.41   | 0.417|0.606    |0.606    |0.606|\n",
    "|Entropy|Normal|No|5k|0.435   | 0.412 |   0.423|0.604   | 0.604    |0.604 |\n",
    "|Entropy|Binary Tree|No|5k|0.423 |   0.305 |   0.354|0.58 |    0.58|     0.58 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Evaluación del mejor modelo obtenido\n",
    "\n",
    "El modelo que presenta mejor resultados entre todos los generados anteriormente es evaluado usando el tercer subconjunto de datos (datos de evaluación).\n",
    "\n",
    "Resultados:\n",
    "\n",
    "Micro/Macro:\n",
    "\n",
    "Matriz de confusión:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Conclusiones\n",
    "\n",
    "Estamos conformes con los resultados obtenidos. Consideramos que haber podido predecir un %%%%% del total de las tuplas considerando la falta de tuplas correspondientes a algunas clases en particular y la cantidad de atributos utilizados en el conjunto de datos.\n",
    "\n",
    "Creemos que podríamos haber realizado un mejor tratamiento previo de los datos de forma de garantizar un conjunto de entrenamiento con una distribución homogénea de clases y, de ser posible, también de valores de sus atributos, para así tener un conjunto de entrenamiento ideal para generar el árbol de decisiones.\n",
    "\n",
    "Haber permitido la reutilización de atributos incrementó significativamente el porcentaje de aciertos. Un analisis mas profundo sobre el umbral utilizado para descartar un atributo podría dar mejores resultados aún.\n",
    "\n",
    "\n",
    "PARA CONCLUSION:\n",
    "- Analizar proporcion de mejoría en relación al aumento de tuplas de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
